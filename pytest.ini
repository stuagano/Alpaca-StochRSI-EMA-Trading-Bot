[tool:pytest]
# Enhanced pytest configuration for comprehensive trading bot testing

# Test discovery patterns
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test directories
testpaths = tests

# Minimum version requirement
minversion = 7.0

# Add options for test execution
addopts = 
    -v
    --strict-markers
    --strict-config
    --tb=short
    --cov=.
    --cov-branch
    --cov-report=html:tests/reports/htmlcov
    --cov-report=term-missing
    --cov-report=xml:tests/reports/coverage.xml
    --cov-report=json:tests/reports/coverage.json
    --cov-fail-under=80
    --durations=20
    --maxfail=3
    --junit-xml=tests/reports/junit.xml
    --html=tests/reports/report.html
    --self-contained-html
    --benchmark-only
    --benchmark-json=tests/reports/benchmark.json
    --tb=line

# Markers for comprehensive test categorization
markers =
    unit: Unit tests for individual components
    integration: Integration tests for component interactions
    e2e: End-to-end tests simulating full trading workflows
    slow: Tests that take a long time to run (>5 seconds)
    fast: Fast tests that run in under 1 second
    network: Tests that require network access
    api: Tests that interact with external APIs
    alpaca: Tests specific to Alpaca API integration
    database: Tests that require database access
    risk: Tests related to risk management functionality
    trading: Tests related to trading operations
    data: Tests related to data management and processing
    strategy: Tests related to trading strategies
    stochrsi: Tests specific to StochRSI strategy
    ma_crossover: Tests specific to MA crossover strategy
    performance: Performance and benchmark tests
    memory: Memory usage and leak detection tests
    security: Security and vulnerability tests
    config: Configuration-related tests
    fixtures: Tests for data fixtures and mocks
    regression: Regression tests for known issues
    smoke: Basic smoke tests for core functionality
    critical: Critical path tests that must always pass
    monitoring: Tests for monitoring and alerting
    backtest: Backtesting related tests
    realtime: Real-time data processing tests
    portfolio: Portfolio management tests
    orders: Order management and execution tests
    indicators: Technical indicator calculation tests
    ml: Machine learning model tests
    cleanup: Tests that verify proper resource cleanup

# Test execution configuration
# Parallel execution (uncomment for faster test runs)
# addopts = -n auto

# Coverage configuration with enhanced settings
[coverage:run]
source = .
parallel = true
branch = true
concurrency = multiprocessing
data_file = tests/reports/.coverage

omit = 
    */tests/*
    */test_*
    */venv/*
    */env/*
    */node_modules/*
    */__pycache__/*
    */migrations/*
    */static/*
    */media/*
    */templates/*
    */worktrees/*
    setup.py
    manage.py
    */settings/*
    */wsgi.py
    */asgi.py
    config_params.py
    run.py
    run_tests.py
    */coordination/*
    */memory/*
    */docs/*

[coverage:report]
precision = 2
show_missing = true
skip_covered = false
sort = Cover

exclude_lines =
    pragma: no cover
    def __repr__
    def __str__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod
    @abstractmethod
    # Type checking imports
    if TYPE_CHECKING:
    if typing.TYPE_CHECKING:

[coverage:html]
directory = tests/reports/htmlcov
title = Trading Bot Test Coverage Report

[coverage:xml]
output = tests/reports/coverage.xml

[coverage:json]
output = tests/reports/coverage.json

# Enhanced warning filters
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore:.*pandas.*:FutureWarning
    ignore:.*numpy.*:FutureWarning
    ignore:.*sklearn.*:FutureWarning
    ignore:.*tensorflow.*:FutureWarning
    ignore:.*torch.*:FutureWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore::ResourceWarning
    error::pytest.PytestConfigWarning

# Test execution timeout and collection
timeout = 600
timeout_method = thread
collect_ignore = ["setup.py", "venv", "env", "node_modules", "worktrees"]

# Enhanced logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(funcName)s:%(lineno)d - %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# File logging during tests
log_file = tests/reports/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(funcName)s:%(lineno)d - %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Capture configuration
log_capture = true
log_level = INFO
capture = no

# JUnit XML output for CI systems
junit_family = xunit2
junit_logging = all
junit_log_passing_tests = true
junit_duration_report = total

# Temporary directory management
tmp_path_retention_count = 5
tmp_path_retention_policy = failed

# Test session configuration
console_output_style = progress
verbosity_test_cases = 2

# Performance testing configuration
benchmark_min_rounds = 3
benchmark_max_time = 10.0
benchmark_min_time = 0.005
benchmark_warmup = true
benchmark_warmup_iterations = 3
benchmark_disable_gc = false
benchmark_sort = min

# Asyncio configuration for async tests
asyncio_mode = auto

# Cache configuration
cache_dir = tests/.pytest_cache